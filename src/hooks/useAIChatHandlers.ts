import { Message } from '@/components/chat/AIChatMessages';
import { useToast } from '@/hooks/use-toast';
import { useTranslation } from '@/hooks/useTranslation';

interface UseAIChatHandlersProps {
  apiKey?: string;
  model: string;
  messages: Message[];
  setMessages: React.Dispatch<React.SetStateAction<Message[]>>;
  input: string;
  setInput: React.Dispatch<React.SetStateAction<string>>;
  uploadedFiles: {name: string; content: string; type: 'text' | 'image'; dataUrl?: string}[];
  setUploadedFiles: React.Dispatch<React.SetStateAction<{name: string; content: string; type: 'text' | 'image'; dataUrl?: string}[]>>;
  setIsLoading: React.Dispatch<React.SetStateAction<boolean>>;
  setShowQuickPrompts: React.Dispatch<React.SetStateAction<boolean>>;
  setTotalTokens: React.Dispatch<React.SetStateAction<number>>;
  fileInputRef: React.RefObject<HTMLInputElement>;
  imageInputRef: React.RefObject<HTMLInputElement>;
}

export function useAIChatHandlers({
  apiKey,
  model,
  messages,
  setMessages,
  input,
  setInput,
  uploadedFiles,
  setUploadedFiles,
  setIsLoading,
  setShowQuickPrompts,
  setTotalTokens,
  fileInputRef,
  imageInputRef
}: UseAIChatHandlersProps) {
  const { toast } = useToast();
  const { t } = useTranslation();

  const handleFileUpload = async (e: React.ChangeEvent<HTMLInputElement>, type: 'text' | 'image') => {
    const files = e.target.files;
    if (!files || files.length === 0) return;

    const newFiles: {name: string; content: string; type: 'text' | 'image'; dataUrl?: string}[] = [];
    
    for (let i = 0; i < files.length; i++) {
      const file = files[i];
      if (file.size > 5 * 1024 * 1024) {
        toast({
          title: t.errors.fileTooLarge,
          description: `${file.name} ${t.errors.fileExceeds}`,
          variant: 'destructive'
        });
        continue;
      }

      try {
        if (type === 'image') {
          const reader = new FileReader();
          const dataUrl = await new Promise<string>((resolve, reject) => {
            reader.onload = () => resolve(reader.result as string);
            reader.onerror = reject;
            reader.readAsDataURL(file);
          });
          newFiles.push({ name: file.name, content: '', type: 'image', dataUrl });
        } else {
          const text = await file.text();
          newFiles.push({ name: file.name, content: text, type: 'text' });
        }
      } catch (error) {
        toast({
          title: t.errors.fileReadError,
          description: file.name,
          variant: 'destructive'
        });
      }
    }

    if (newFiles.length > 0) {
      setUploadedFiles(prev => [...prev, ...newFiles]);
      toast({
        title: `${t.errors.filesUploaded}: ${newFiles.length}`,
        description: newFiles.map(f => f.name).join(', ')
      });
    }
    
    if (fileInputRef.current) fileInputRef.current.value = '';
    if (imageInputRef.current) imageInputRef.current.value = '';
  };

  const removeFile = (index: number) => {
    setUploadedFiles(prev => prev.filter((_, i) => i !== index));
    toast({ title: t.errors.fileRemoved });
  };

  const sendMessageViaFallback = async (userMessage: Message, storedApiKey: string): Promise<Message> => {
    const savedSettings = localStorage.getItem('site_settings');
    const fallbackModel = savedSettings ? JSON.parse(savedSettings).fallbackAiModel : 'meta-llama/llama-3.3-70b-instruct:free';

    if (!fallbackModel) {
      throw new Error('FALLBACK_NOT_CONFIGURED');
    }

    const response = await fetch('https://openrouter.ai/api/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${storedApiKey}`,
        'Content-Type': 'application/json',
        'HTTP-Referer': window.location.origin,
        'X-Title': 'AI Chat Assistant'
      },
      body: JSON.stringify({
        model: fallbackModel,
        messages: [...messages, userMessage].map(m => {
          if (m.files && m.files.some(f => f.type === 'image')) {
            const content: any[] = [{ type: 'text', text: m.content }];
            m.files.filter(f => f.type === 'image' && f.dataUrl).forEach(img => {
              content.push({
                type: 'image_url',
                image_url: { url: img.dataUrl }
              });
            });
            return { role: m.role, content };
          }
          return { role: m.role, content: m.content };
        })
      })
    });

    if (!response.ok) {
      const error = await response.json();
      throw new Error(error.error?.message || 'Fallback API error');
    }

    const data = await response.json();
    return {
      role: 'assistant',
      content: data.choices[0].message.content,
      timestamp: Date.now()
    };
  };

  const sendMessage = async (customMessage?: string) => {
    const messageToSend = customMessage || input;
    if (!messageToSend.trim() && uploadedFiles.length === 0) return;

    const storedApiKey = apiKey || localStorage.getItem('openrouter_api_key');
    
    if (!storedApiKey) {
      const errorMsg: Message = {
        role: 'assistant',
        content: `‚ùå **API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω**\n\nüìù **–ö–∞–∫ –∏—Å–ø—Ä–∞–≤–∏—Ç—å:**\n\n1. –ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É **‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏** –≤ –≤–µ—Ä—Ö–Ω–µ–π –ø–∞–Ω–µ–ª–∏\n2. –í–≤–µ–¥–∏—Ç–µ –ø–∞—Ä–æ–ª—å: **bogdan2025**\n3. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –≤ —Ä–∞–∑–¥–µ–ª **"–ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–∞–π—Ç–∞"**\n4. –ü—Ä–æ–∫—Ä—É—Ç–∏—Ç–µ –≤–Ω–∏–∑ –¥–æ **"–ù–∞—Å—Ç—Ä–æ–π–∫–∏ AI —á–∞—Ç-–±–æ—Ç–∞"**\n5. –í—Å—Ç–∞–≤—å—Ç–µ **OpenRouter API –∫–ª—é—á**\n   - –ü–æ–ª—É—á–∏—Ç—å –±–µ—Å–ø–ª–∞—Ç–Ω–æ: [openrouter.ai/keys](https://openrouter.ai/keys)\n6. –ù–∞–∂–º–∏—Ç–µ **"–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏"**\n\nüí° –ü–æ—Å–ª–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —á–∞—Ç –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å!`,
        timestamp: Date.now()
      };
      setMessages(prev => [...prev, errorMsg]);
      
      toast({
        title: `‚ùå API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω`,
        description: `–ó–∞–π–¥–∏—Ç–µ –≤ –∞–¥–º–∏–Ω-–ø–∞–Ω–µ–ª—å (‚öôÔ∏è) ‚Üí –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–∞–π—Ç–∞`,
        variant: 'destructive',
        duration: 8000
      });
      return;
    }

    const textFiles = uploadedFiles.filter(f => f.type === 'text');
    const imageFiles = uploadedFiles.filter(f => f.type === 'image');
    
    let fullContent = messageToSend;
    if (textFiles.length > 0) {
      fullContent += '\n\nüìé –ü—Ä–∏–∫—Ä–µ–ø–ª—ë–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã:\n\n';
      textFiles.forEach(file => {
        fullContent += `--- ${file.name} ---\n${file.content}\n\n`;
      });
    }
    
    if (imageFiles.length > 0) {
      fullContent += `\n\nüñºÔ∏è –ü—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: ${imageFiles.length}\n`;
      imageFiles.forEach(file => {
        fullContent += `üì∑ ${file.name}\n`;
      });
    }

    const userMessage: Message = { 
      role: 'user', 
      content: fullContent,
      timestamp: Date.now(),
      files: uploadedFiles.length > 0 ? [...uploadedFiles] : undefined
    };
    setMessages(prev => [...prev, userMessage]);
    setInput('');
    setUploadedFiles([]);
    setIsLoading(true);
    setShowQuickPrompts(false);

    try {
      const response = await fetch('https://openrouter.ai/api/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${storedApiKey}`,
          'Content-Type': 'application/json',
          'HTTP-Referer': window.location.origin,
          'X-Title': 'AI Chat Assistant'
        },
        body: JSON.stringify({
          model: model,
          messages: [...messages, userMessage].map(m => {
            if (m.files && m.files.some(f => f.type === 'image')) {
              const content: any[] = [{ type: 'text', text: m.content }];
              m.files.filter(f => f.type === 'image' && f.dataUrl).forEach(img => {
                content.push({
                  type: 'image_url',
                  image_url: { url: img.dataUrl }
                });
              });
              return { role: m.role, content };
            }
            return { role: m.role, content: m.content };
          })
        })
      });

      if (!response.ok) {
        let errorMsg = 'API request failed';
        try {
          const error = await response.json();
          errorMsg = error.error?.message || error.message || errorMsg;
        } catch (e) {
          errorMsg = `HTTP ${response.status}`;
        }
        
        if (response.status === 401) {
          throw new Error(t.errors.invalidApiKey);
        }
        
        if (response.status === 402) {
          throw new Error(t.errors.insufficientCredits);
        }
        
        if (response.status === 404) {
          throw new Error(t.errors.modelNotFound);
        }
        
        if (response.status === 429) {
          throw new Error('RATE_LIMIT_429');
        }
        
        throw new Error(errorMsg);
      }

      const data = await response.json();
      const aiResponse: Message = {
        role: 'assistant',
        content: data.choices[0].message.content,
        timestamp: Date.now()
      };

      if (data.usage) {
        setTotalTokens(prev => prev + (data.usage.total_tokens || 0));
      }

      setMessages(prev => [...prev, aiResponse]);
      
      toast({
        title: `‚úì ${t.errors.responseReceived}`,
        description: `${t.errors.tokensUsed}: ${data.usage?.total_tokens || 0}`,
      });
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : t.errors.failedToGetResponse;
      
      if (errorMessage === 'RATE_LIMIT_429') {
        try {
          const savedSettings = localStorage.getItem('site_settings');
          const fallbackModel = savedSettings ? JSON.parse(savedSettings).fallbackAiModel : 'meta-llama/llama-3.3-70b-instruct:free';
          
          toast({
            title: `üîÑ –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω—É—é –º–æ–¥–µ–ª—å...`,
            description: `–û—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω–∞, –ø—Ä–æ–±—É—é ${fallbackModel}`,
          });

          const userMessage: Message = { 
            role: 'user', 
            content: messageToSend,
            timestamp: Date.now()
          };

          const fallbackResponse = await sendMessageViaFallback(userMessage, storedApiKey!);
          setMessages(prev => [...prev, fallbackResponse]);
          
          toast({
            title: `‚úÖ –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω —á–µ—Ä–µ–∑ —Ä–µ–∑–µ—Ä–≤–Ω—É—é –º–æ–¥–µ–ª—å`,
            description: `–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –º–æ–¥–µ–ª—å: ${fallbackModel}`,
          });
          
          setIsLoading(false);
          return;
        } catch (fallbackError) {
          const fallbackErrorMsg = fallbackError instanceof Error ? fallbackError.message : 'Unknown error';
          
          if (fallbackErrorMsg === 'FALLBACK_NOT_CONFIGURED') {
            toast({
              title: `‚ùå –†–µ–∑–µ—Ä–≤–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞`,
              description: `–ù–∞—Å—Ç—Ä–æ–π—Ç–µ —Ä–µ–∑–µ—Ä–≤–Ω—É—é –º–æ–¥–µ–ª—å –≤ –∞–¥–º–∏–Ω-–ø–∞–Ω–µ–ª–∏`,
              variant: 'destructive',
              duration: 10000
            });
            
            const errorMsg: Message = {
              role: 'assistant',
              content: `‚ùå **–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ (429)**\n\nüîÑ **–ü–æ–ø—ã—Ç–∫–∞ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è –Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω—É—é –º–æ–¥–µ–ª—å –ø—Ä–æ–≤–∞–ª–∏–ª–∞—Å—å**\n\n---\n\nüìù **–†–µ—à–µ–Ω–∏—è:**\n\n**–í–∞—Ä–∏–∞–Ω—Ç 1: –ù–∞—Å—Ç—Ä–æ–∏—Ç—å —Ä–µ–∑–µ—Ä–≤–Ω—É—é –º–æ–¥–µ–ª—å (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)**\n1. –û—Ç–∫—Ä–æ–π—Ç–µ **‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏** ‚Üí **–ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–∞–π—Ç–∞**\n2. –ù–∞–π–¥–∏—Ç–µ **"–†–µ–∑–µ—Ä–≤–Ω–∞—è –º–æ–¥–µ–ª—å AI"**\n3. –í—ã–±–µ—Ä–∏—Ç–µ –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å (–Ω–∞–ø—Ä–∏–º–µ—Ä, Llama 3.3 70B)\n4. –ü—Ä–∏ –æ—à–∏–±–∫–µ 429 —á–∞—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—Å—è\n\n**–í–∞—Ä–∏–∞–Ω—Ç 2: –ü–æ–¥–æ–∂–¥–∞—Ç—å**\n- –ü–æ–¥–æ–∂–¥–∏—Ç–µ 1-2 –º–∏–Ω—É—Ç—ã\n- –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞\n\n**–í–∞—Ä–∏–∞–Ω—Ç 3: –ü–æ–ø–æ–ª–Ω–∏—Ç—å –±–∞–ª–∞–Ω—Å**\n- –ü–æ–ø–æ–ª–Ω–∏—Ç–µ $5 –Ω–∞ [openrouter.ai](https://openrouter.ai)\n- –ü–ª–∞—Ç–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –±–µ–∑ –ª–∏–º–∏—Ç–æ–≤`,
              timestamp: Date.now()
            };
            setMessages(prev => [...prev, errorMsg]);
            setIsLoading(false);
            return;
          }
          
          toast({
            title: `‚ùå –û—à–∏–±–∫–∞ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –º–æ–¥–µ–ª–∏`,
            description: fallbackErrorMsg,
            variant: 'destructive',
            duration: 8000
          });
          
          const errorMsg: Message = {
            role: 'assistant',
            content: `‚ùå **–û—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω–∞ (429)**\n‚ùå **–†–µ–∑–µ—Ä–≤–Ω–∞—è –º–æ–¥–µ–ª—å —Ç–æ–∂–µ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∞**\n\n**–û—à–∏–±–∫–∞:** ${fallbackErrorMsg}\n\n---\n\nüìù **–†–µ—à–µ–Ω–∏–µ:**\n1. –ü–æ–¥–æ–∂–¥–∏—Ç–µ 1-2 –º–∏–Ω—É—Ç—ã\n2. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö\n3. –ò–ª–∏ –ø–æ–ø–æ–ª–Ω–∏—Ç–µ –±–∞–ª–∞–Ω—Å –Ω–∞ openrouter.ai ($5)`,
            timestamp: Date.now()
          };
          setMessages(prev => [...prev, errorMsg]);
          setIsLoading(false);
          return;
        }
      }
      
      let helpText = '';
      if (errorMessage.includes('401') || errorMessage.includes('Invalid')) {
        helpText = '\n\n**–†–µ—à–µ–Ω–∏–µ:** –ü—Ä–æ–≤–µ—Ä—å—Ç–µ API –∫–ª—é—á –≤ –∞–¥–º–∏–Ω-–ø–∞–Ω–µ–ª–∏ (‚öôÔ∏è ‚Üí –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–∞–π—Ç–∞)';
      } else if (errorMessage.includes('402') || errorMessage.includes('credits')) {
        helpText = '\n\n**–†–µ—à–µ–Ω–∏–µ:** –ü–æ–ø–æ–ª–Ω–∏—Ç–µ –±–∞–ª–∞–Ω—Å –Ω–∞ openrouter.ai –∏–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ –±–µ—Å–ø–ª–∞—Ç–Ω—É—é –º–æ–¥–µ–ª—å';
      } else if (errorMessage.includes('404') || errorMessage.includes('model')) {
        helpText = '\n\n**–†–µ—à–µ–Ω–∏–µ:** –ò–∑–º–µ–Ω–∏—Ç–µ –º–æ–¥–µ–ª—å –≤ –∞–¥–º–∏–Ω-–ø–∞–Ω–µ–ª–∏ (‚öôÔ∏è ‚Üí –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–∞–π—Ç–∞ ‚Üí –ú–æ–¥–µ–ª—å AI)';
      } else {
        helpText = '\n\n**–†–µ—à–µ–Ω–∏–µ:** –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∏ API –∫–ª—é—á';
      }
      
      toast({
        title: `‚ùå –û—à–∏–±–∫–∞ API`,
        description: errorMessage,
        variant: 'destructive',
        duration: 8000
      });
      
      const errorMsg: Message = {
        role: 'assistant',
        content: `‚ùå **–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ AI**\n\n**–î–µ—Ç–∞–ª–∏:** ${errorMessage}${helpText}\n\n---\n\nüìù **–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ:**\n1. –ù–∞–∂–º–∏—Ç–µ **‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏** ‚Üí –≤–≤–µ–¥–∏—Ç–µ –ø–∞—Ä–æ–ª—å **bogdan2025**\n2. –ü—Ä–æ–∫—Ä—É—Ç–∏—Ç–µ –¥–æ **"–ù–∞—Å—Ç—Ä–æ–π–∫–∏ AI —á–∞—Ç-–±–æ—Ç–∞"**\n3. –í—Å—Ç–∞–≤—å—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π **OpenRouter API –∫–ª—é—á**\n4. –í—ã–±–µ—Ä–∏—Ç–µ **–±–µ—Å–ø–ª–∞—Ç–Ω—É—é –º–æ–¥–µ–ª—å** (Google Gemini 2.0 Flash)\n5. –°–æ—Ö—Ä–∞–Ω–∏—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏`,
        timestamp: Date.now()
      };
      setMessages(prev => [...prev, errorMsg]);
    } finally {
      setIsLoading(false);
    }
  };

  const clearHistory = () => {
    setMessages([]);
    localStorage.removeItem('ai_chat_history');
    setTotalTokens(0);
    setShowQuickPrompts(true);
    toast({ title: t.notifications.historyCleared });
  };

  const copyMessage = (content: string) => {
    navigator.clipboard.writeText(content);
    toast({ title: t.notifications.messageCopied });
  };

  const exportChat = () => {
    const chatData = messages.map(m => `${m.role === 'user' ? '–í—ã' : 'AI'}: ${m.content}`).join('\n\n');
    const blob = new Blob([chatData], { type: 'text/plain' });
    const url = URL.createObjectURL(blob);
    const a = document.createElement('a');
    a.href = url;
    a.download = `ai-chat-${Date.now()}.txt`;
    a.click();
    toast({ title: t.notifications.chatExported });
  };

  return {
    handleFileUpload,
    removeFile,
    sendMessage,
    clearHistory,
    copyMessage,
    exportChat
  };
}